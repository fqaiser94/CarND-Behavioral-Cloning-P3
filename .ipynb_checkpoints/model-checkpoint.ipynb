{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things to do:  \n",
    "\n",
    "1. Collect more data by going round Track 1 counter clockwise.   \n",
    "2. Collect more data by going on Track 2.  \n",
    "3. Possibly try using throttle data ....\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data location for local machine\n",
    "data_loc = '/media/fqaiser94/ff3daf1f-fc36-43a4-a218-478126941f2a/behavioral-data/'\n",
    "\n",
    "# set data location for AWS\n",
    "#data_loc = '/behavioral-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read images and angles into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with open(data_loc + 'driving_log.csv') as csv_file: \n",
    "    \n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    for line in reader: \n",
    "        \n",
    "        lines.append(line)    \n",
    "\n",
    "# remove header row\n",
    "lines = lines[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "angles = []\n",
    "            \n",
    "correction = 0.2\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    # there are 3 images in each row\n",
    "    # each corresponding to the center, left and right cameras respectively\n",
    "    for i in range(3): \n",
    "                    \n",
    "        # get image in column j of row line \n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        path = data_loc + 'IMG/' + filename\n",
    "        image = cv2.imread(path)\n",
    "\n",
    "        # get angle associated with image in column j of row line \n",
    "        # add correction to angle based on the camera from which image came from\n",
    "        angle = float(line[3])\n",
    "        \n",
    "        if i==0:\n",
    "            angle = angle\n",
    "        elif i==1:\n",
    "            angle = angle + correction\n",
    "        elif i==2:\n",
    "            angle = angle - correction\n",
    "        \n",
    "        # add image/angle to list\n",
    "        images.append(image)\n",
    "        angles.append(angle)\n",
    "        \n",
    "images = np.array(images)\n",
    "angles = np.array(angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histogram of angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4kosqspTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f962cce77b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "\n",
    "num_bins = 30\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(angles, num_bins, normed=1, facecolor='blue', alpha=0.5)\n",
    " \n",
    "# add a 'best fit' line\n",
    "mu = np.mean(angles)\n",
    "sigma = np.std(angles)\n",
    "y = mlab.normpdf(bins, mu, sigma)\n",
    "\n",
    "plt.plot(bins, y)\n",
    "plt.xlabel('Steering Angle')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of steering angles')\n",
    " \n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vast majority of steering angles are focused in the middle.  \n",
    "This will bias our car toward steering down the middle.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image flip\n",
    "To combat this bias, we'll do flip some images to create \"new\" images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.212070522123\n",
      "-0.203931233993\n"
     ]
    }
   ],
   "source": [
    "angle_max = mu + sigma\n",
    "angle_min = mu - sigma\n",
    "\n",
    "print(angle_max)\n",
    "print(angle_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24108, 160, 320, 3)\n",
      "(24108,)\n",
      "(5559, 160, 320, 3)\n",
      "(28667,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.where((angles > angle_max) | (angles < angle_min))\n",
    "\n",
    "images_flipped = np.fliplr(images[temp])\n",
    "angles_flipped = -angles[temp]\n",
    "\n",
    "temp_images = np.vstack((images, images_flipped))\n",
    "temp_angles = np.hstack((angles, angles_flipped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_bins = np.digitize(angles, bins)\n",
    "angles_y = np.array([y[i-1] for i in angles_bins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14500,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = np.array([])\n",
    "\n",
    "for bin_number in np.unique(angles_bins): \n",
    "    \n",
    "    i = np.where(angles_bins==bin_number)\n",
    "    i = np.array(i).flatten()\n",
    "    i_random = np.random.choice(a=i, size=500,replace=True)\n",
    "\n",
    "    new = np.hstack((new, i_random))\n",
    "    \n",
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_uni_sample = np.array([images[int(i)] for i in new])\n",
    "angles_uni_sample = np.array([angles[int(i)] for i in new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f420c2e25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 30\n",
    "\n",
    "n, bins, patches = plt.hist(angles_uni_sample, num_bins, normed=1, facecolor='blue', alpha=0.5)\n",
    "\n",
    "# plt.plot(bins, y)\n",
    "plt.xlabel('Steering Angle')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of steering angles')\n",
    " \n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator\n",
    "\n",
    "Too much data to fit into memory.  \n",
    "We will use a generator to 'yield' data as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake  \\\n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
       "\n",
       "       speed  \n",
       "0  22.148290  \n",
       "1  21.879630  \n",
       "2   1.453011  \n",
       "3   1.438419  \n",
       "4   1.418236  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df = pd.read_csv(data_loc + 'driving_log.csv', index_col=False)\n",
    "\n",
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define training and valdidation data  \n",
    "(we don't need test data as we will simply get our model to drive a car around a track for testing purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 8036\n",
      "\n",
      "Training samples: 6428\n",
      "Validation samples: 1608\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(csv_df)\n",
    "training_count = int(0.8 * total_samples)\n",
    "\n",
    "training_data = csv_df[:training_count].reset_index()\n",
    "validation_data = csv_df[training_count:].reset_index()\n",
    "\n",
    "print('Total number of samples: %s' %total_samples)\n",
    "print('')\n",
    "print('Training samples: %s' %len(training_data))\n",
    "print('Validation samples: %s' %len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake  \\\n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
       "\n",
       "       speed  \n",
       "0  22.148290  \n",
       "1  21.879630  \n",
       "2   1.453011  \n",
       "3   1.438419  \n",
       "4   1.418236  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24108\n",
      "24108\n"
     ]
    }
   ],
   "source": [
    "images_paths = []\n",
    "steering_angles = []\n",
    "camera = []\n",
    "\n",
    "angle_shift_dict = dict({\n",
    "        'left': 0.25, \n",
    "        'center': 0.00, \n",
    "        'right': -0.25\n",
    "    })\n",
    "\n",
    "for i in ['left', 'center', 'right']: \n",
    "    \n",
    "    image_path = csv_df[i].tolist()\n",
    "    \n",
    "    angle_shift = angle_shift_dict.get(i)\n",
    "    angle = csv_df['steering'] + angle_shift\n",
    "    \n",
    "    images_paths.extend(image_path)\n",
    "    steering_angles.extend(angle)\n",
    "    \n",
    "print(len(images_paths))\n",
    "print(len(steering_angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>steering_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_path  steering_angle\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg            0.25\n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg            0.25\n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg            0.25\n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg            0.25\n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg            0.25"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make normalized df\n",
    "all_data =  pd.DataFrame({'image_path': images_paths, \n",
    "                          'steering_angle': angles})\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size):\n",
    "    \"\"\"\n",
    "    Returns randomly sampled data from given pandas df  .  \n",
    "    \"\"\"\n",
    "    return data.sample(n=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(data, \n",
    "              data_path, \n",
    "              index):\n",
    "    \"\"\"\n",
    "    get image and angle\n",
    "    \"\"\"\n",
    "    \n",
    "    image_path = data['image_path'][index].strip()\n",
    "    print(image_path)\n",
    "    image = cv2.imread(os.path.join(data_path, image_path))\n",
    "    \n",
    "    steering_angle = float(data['steering_angle'][index])\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image(image_data, steering_data): \n",
    "    \n",
    "    temp = np.where((angles > angle_max) | (angles < angle_min))\n",
    "\n",
    "    images_flipped = np.fliplr(images[temp])\n",
    "    angles_flipped = -angles[temp]\n",
    "\n",
    "    temp_images = np.vstack((images, images_flipped))\n",
    "    temp_angles = np.hstack((angles, angles_flipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG/left_2016_12_01_13_30_48_287.jpg\n",
      "IMG/left_2016_12_01_13_30_48_404.jpg\n",
      "IMG/left_2016_12_01_13_31_12_937.jpg\n",
      "IMG/left_2016_12_01_13_31_13_037.jpg\n",
      "IMG/left_2016_12_01_13_31_13_177.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in (all_data.head().index.values):\n",
    "    \n",
    "    image, steering_angle  = get_image(data = all_data, data_path = data_loc, index = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, data_path, batch_size):\n",
    "    \"\"\"\n",
    "    generates image and label data\n",
    "    \"\"\"\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        batch = get_batch(data, batch_size)\n",
    "        \n",
    "        features = np.empty([batch_size, 75, 320, 3])\n",
    "        labels = np.empty([batch_size, 1])\n",
    "        \n",
    "        for i in (all_data.index.values):\n",
    "    \n",
    "            image, steering_angle  = get_image(data = data, \n",
    "                                               data_path = data_path, \n",
    "                                               index = i)\n",
    "                        \n",
    "            features[i] = image\n",
    "            labels[i] = steering_angle\n",
    "            \n",
    "            yield np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "samples = []\n",
    "\n",
    "with open(data_loc + 'driving_log.csv') as csv_file: \n",
    "    \n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    \n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    # Loop forever so the generator never terminates\n",
    "    while 1: \n",
    "        \n",
    "        shuffle(samples)\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            \n",
    "            correction = 0.2\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                for i in range(3): \n",
    "                    # this is to get center, left and right images\n",
    "\n",
    "                    path = data_loc + 'IMG/' + batch_sample[i].split('/')[-1]\n",
    "                    image = cv2.imread(path)\n",
    "                    \n",
    "                    angle = float(batch_sample[3])\n",
    "                    \n",
    "                    # add correction to angle based on image\n",
    "                    if i==1:\n",
    "                        angle = angle + correction\n",
    "                    \n",
    "                    elif i==2:\n",
    "                        angle = angle - correction                    \n",
    "                    \n",
    "                    # add image and associated angle to list\n",
    "                    images.append(image)\n",
    "                    angles.append(angle)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:37: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., validation_steps=1608, steps_per_epoch=6429, validation_data=<generator..., verbose=1, epochs=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   8/6429 [..............................] - ETA: 24:46 - loss: 6.3666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fca6e5c92c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                                      \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                      \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                                     )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2081\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Convolution2D\n",
    "\n",
    "\n",
    "# generate\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "# init\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, \n",
    "                 input_shape=(160,320,3),\n",
    "                 output_shape=(160,320,3)\n",
    "                )\n",
    "         )\n",
    "\n",
    "# crop images to reduce noise, returns img of shape (80,320,3)\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "\n",
    "# flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully-connected\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit  \n",
    "history_object = model.fit_generator(generator = train_generator, \n",
    "                                     samples_per_epoch = len(train_samples), \n",
    "                                     validation_data = validation_generator,\n",
    "                                     nb_val_samples = len(validation_samples), \n",
    "                                     nb_epoch=5, \n",
    "                                     verbose=1\n",
    "                                    )\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced model \n",
    "\n",
    "Our model will be based on an architecture previously developed at NVIDIA.  \n",
    "\n",
    "![NVIDIA Self Driving Car Architecture](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/08/cnn-architecture-624x890.png)\n",
    "\n",
    "For more information, see the following [link](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nVidiaModel():\n",
    "    \"\"\"\n",
    "    Creates nVidea Autonomous Car Group model\n",
    "    \"\"\"\n",
    "    \n",
    "    # init\n",
    "    model = Sequential()\n",
    "\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "    # crop images to reduce noise, returns img of shape (80,320,3)\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "    \n",
    "    model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  app.launch_new_instance()\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., validation_steps=1608, steps_per_epoch=6429, validation_data=<generator..., verbose=1, epochs=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   7/6429 [..............................] - ETA: 2:02:47 - loss: 0.0866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2bfc09ec02d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                      \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                                     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "\n",
    "# generate\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "# generate model\n",
    "model = nVidiaModel()\n",
    "\n",
    "# fit  \n",
    "history_object = model.fit_generator(generator = train_generator, \n",
    "                                     samples_per_epoch = len(train_samples), \n",
    "                                     validation_data = validation_generator,\n",
    "                                     nb_val_samples = len(validation_samples), \n",
    "                                     nb_epoch=5, \n",
    "                                     verbose=1\n",
    "                                    )\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
