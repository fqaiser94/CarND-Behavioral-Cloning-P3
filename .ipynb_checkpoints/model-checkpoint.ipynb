{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other things to do:  \n",
    "\n",
    "1. Collect more data by going round Track 1 counter clockwise.   \n",
    "2. Collect more data by going on Track 2.  \n",
    "3. Possibly try using throttle data ....\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data location for local machine\n",
    "data_loc = '/media/fqaiser94/ff3daf1f-fc36-43a4-a218-478126941f2a/behavioral-data/'\n",
    "\n",
    "# set data location for AWS\n",
    "#data_loc = '/behavioral-data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read images and angles into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "with open(data_loc + 'driving_log.csv') as csv_file: \n",
    "    \n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    for line in reader: \n",
    "        \n",
    "        lines.append(line)    \n",
    "\n",
    "# remove header row\n",
    "lines = lines[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "angles = []\n",
    "            \n",
    "correction = 0.2\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    # there are 3 images in each row\n",
    "    # each corresponding to the center, left and right cameras respectively\n",
    "    for i in range(3): \n",
    "                    \n",
    "        # get image in column j of row line \n",
    "        source_path = line[i]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        path = data_loc + 'IMG/' + filename\n",
    "        image = cv2.imread(path)\n",
    "\n",
    "        # get angle associated with image in column j of row line \n",
    "        # add correction to angle based on the camera from which image came from\n",
    "        angle = float(line[3])\n",
    "        \n",
    "        if i==0:\n",
    "            angle = angle\n",
    "        elif i==1:\n",
    "            angle = angle + correction\n",
    "        elif i==2:\n",
    "            angle = angle - correction\n",
    "        \n",
    "        # add image/angle to list\n",
    "        images.append(image)\n",
    "        angles.append(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some image flipping for better generalization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_flipped = np.fliplr(image)\n",
    "# measurement_flipped = -measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histogram of angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZLUMRwkSR3DQZLU+V+3bfK4kzfMeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe51a573b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(angles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYFfXZ//H3vUsv0hEEZCk2sKEoYseKkhhQYiRGo6KI\nLSYm/p48jylqNMYnPhpLDCJygSZRNJagorCIPYBSVAJYWIqASO9lgd3798cMulm2nGXPnDnl87qu\nc502O+dzttw75zvfucfcHRERyV55cQcQEZFoqdCLiGQ5FXoRkSynQi8ikuVU6EVEspwKvYhIllOh\nFxHJcir0IiJZToVeRCTL1Yk7QE21bt3aCwoK4o4hIhK7mTNnrnH3NtUtl3GFvqCggBkzZsQdQ0Qk\ndma2JJHlNHQjIpLlVOhFRLKcCr2ISJZToRcRyXIq9CIiWU6FXkQky6nQi4hkORV6EZEsp0IvIpLl\nMu7IWJFkuf32eL5WJNW0RS8ikuVU6EVEspwKvYhIllOhFxHJcir0IiJZToVeRCTLqdCLiGQ5FXoR\nkSynQi8ikuVU6EVEspwKvYhIllOhFxHJcir0IiJZToVeRCTLqU2xZDy1DBapmgq9SIqpD76kmoZu\nRESynAq9iEiWi6zQm1knM3vTzOaZ2Vwzu7mCZczMHjKzBWb2iZkdE1UeEZFcFeUY/W7g5+4+y8ya\nAjPNrNDd55VZ5jzgoPDSB/hLeC0iIkkS2Ra9u69w91nh7c3AfKBDucW+BzzpgWlAczNrH1UmEZFc\nlJIxejMrAHoB08s91QFYWub+Mvb+ZyAiIrUQeaE3sybA88BP3X3TPq5jmJnNMLMZq1evTm5AEZEs\nF2mhN7O6BEX+b+7+QgWLLAc6lbnfMXzsP7j7SHfv7e6927RpE01YEZEsFeWsGwOeAOa7+/2VLDYe\nuDycfXMCsNHdV0SVSUQkF0U56+Yk4DJgjpl9FD72P8CBAO4+ApgAnA8sALYBV0aYR0QkJ0VW6N39\nPcCqWcaBG6LKICIiOjJWRCTrqdCLiGQ5FXqRGjIvhQ0b4o4hkjAVepEaqLNrO5c/eRYccghs2RJ3\nHJGEqNCL1MDBn79Cl8VvwqpV8Le/xR1HJCEq9CI1MK/n93nk+nlw9NHw5z+De9yRRKqlQi9SDSst\nYcAr19Fp6b8AWNPmMLjhBvjsM/j885jTiVRPhV6kKu5859XrOG7miG8KPQCXXgpLlwZj9SJpTueM\nFamMO/0n/oxjZz3OO6fcxr9O/MW3zzVsGFwASkshT9tMkr702ylSiTOm/IoTpj/I1D4/ZUq/3+29\nQHExnHYa3H136sOJ1IAKvUgFrLSEVus+Z+Yx1zDx3PvBKujmUb8+NGgAjz0Gu3enPqRIglToRcrJ\n312M5+Xz/EVP88qAv1Rc5Pe44QZYvhzGj09dQJEaUqEXKeOYWaO4duQxNN66itK8OnheftVfMGAA\nHHhgMNVSJE2p0IuEjpjzd7778jA2NuvMjgbNE/ui/HwYPhymTIH586MNKLKPNOtGBDh0/osMevFy\nFhecxriLn6ckv17iXzx0KDRtCh07RhdQpBZU6CXndVk0he//4wcs73AcT18ynt11G9ZsBW3bwo03\nRhNOJAk0dCM5b3WbHszteTF/u/Q1dtZvum8rKSmBkSPhhYpOjSwSL23RS85qveZT1rXszpYm7Xjh\nwr/WbmV5eTBiRDDNctCgqmfqiKSYtuglJzXbsIShT/TlnIk/T84KzYKplnPmwHvvJWedIkmiQi85\nqee852i4YwMfHp/EUxYPGQLNm2uqpaQdFXrJSd2KJrGqTU/Wtjo4eStt1AiuvBKefx5WrEjeekVq\nSYVeck7dXdvovOQdirqdk/yVX3cdHHtscGISkTShnbGScw5c8i51SoqjKfQHHQTTpiV/vSK1oC16\nyTmLup7JqKv+xeLOp0X3IuvWBScmEUkD2qKXnFOaV4dlnfpG9wLucNJJcMAB8MYb0b2OSIK0RS85\npcnmFfR/7WZarCuK7kXM4Mc/Vv8bSRsq9JJTuhdN5IQPHqLezi3RvtDQoVCvHjz6aLSvI5IAFXrJ\nKd2KJrGl8f6s3P/IaF+oTRu4+GIYOxY2b472tUSqoUIvOcO8lK4LC4PZNqloUXDDDUGRnzIl+tcS\nqYJ2xkrOaPf1RzTetiaaaZUV6dMHioqga9fUvJ5IJbRFLzljv03L2NK4LUVdz07NC5p9W+RLS1Pz\nmiIV0Ba95IzPDrmAzw7+buo7S15zDWzfDn+tZYdMkX2kLXrJDe7BJY72wfvtB+PGqf+NxEaFXnLC\nwV+8ys0PdaX1mk9T/+LXXRf0qX/88dS/tggq9JIjuhVNosmWlWxoXpD6F+/eHc49Fx57DHbtSv3r\nS85ToZec0K1oEosLTmN3nQbxBLjhBvjqKxg/Pp7Xl5ymQi9Zr9mGJbRe+xlFXVM0rbIi558P99wD\nJ5wQXwbJWZEVejMbbWarzOzflTx/upltNLOPwstvosoiua1b0SQAirqfG1+I/Hz45S+hQ4f4MkjO\ninKLfgzQv5pl3nX3o8PLnRFmkRy2uk0PpvW5mdWtD4s7Crz6KsfOeCzuFJJjIiv07v4OsC6q9Ysk\naumBJ/F6/z/FM7WyvMce48Sp98WdQnJM3GP0fc3sYzN7zcx6xpxFslDTTctpu3JOMIc+HfTrR6t1\nC9hv07K4k0gOibPQzwI6u/tRwMPAS5UtaGbDzGyGmc1YvXp1ygJK5us1ezTXjTiKRtvXxh0lcPrp\nABQsfivWGJJbYiv07r7J3beEtycAdc2sdSXLjnT33u7eu02bNinNKZmte9FEvjrgWLY1qvBXK/WO\nPJLtDZqr0EtKxVbozaydWTBoambHh1nSZLNLskH9HRvpuGwaRd1inG1TXn4+SzqfRvMNi+NOIjkk\nsqZmZvY0cDrQ2syWAb8F6gK4+whgMHCdme0GtgOXuKfLQKpkgy6L3yTPS1LXljhB/xj8THwHbklO\niqzQu/uQap5/BHgkqtcX6VY0ieJ6TVjWMb0OUlKRl1RLaOjGzF4wswFmFvcsHZGETT7rDzx1WSEl\n+fXijrKX7748jLMn3Rp3DMkRiRbuR4EfAl+Y2R/M7JAIM4kkRXH9/dJua36PRttWc9inL8QdQ3JE\nQoXe3Se7+6XAMcBiYLKZ/cvMrjSzulEGFNkXh3w2nlPeuZu8kvTsFrm4oB8t1y+k2cYv444iOSDh\noRgzawVcAVwNzAYeJCj8hZEkE6mFXrNHc8zsUZTmpedJ1BYXnA5oPr2kRqJj9C8C7wKNgO+6+wXu\nPs7dbwKaRBlQpKbySnbRZdGUYFplOrQ9qMCqtoezrWErCha/GXcUyQGJbu48Hh7U9A0zq+/uxe7e\nO4JcIvus4/Lp1N+5Oe2mVZbllsesXkPZ0bBF3FEkByRa6O8CJpR7bCrB0I1IWulWNIlSy2NRlzPi\njlKlyWffG3cEyRFVFnozawd0ABqaWS9gz+fg/QiGcUTSTv3iTSzpfBo7GjSPO0q18kt2Ur94U/q0\naJCsVN0W/bkEO2A7AveXeXwz8D8RZRKpldf7/yl9ulVWxZ0bHzmEJZ1P46WBY+JOI1msykLv7mOB\nsWZ2kbs/n6JMIvvOPdgBm6Y7Yf+DGSvaHxvskN2TWyQC1Q3d/Mjd/woUmNkt5Z939/sr+DKR2Hzn\nleE037iYv/5oYtxRErK44HR6zH+e5hsWs6FFl7jjSJaqbnpl4/C6CdC0gotI+nCne9Hr7KyXOTN+\nFxX0AzSfXqJV3dDNY+H1HamJI7LvWq39nOYbv+TdkzNn99HqNj3Y2qgNBUve4qNeV8YdR7JUdUM3\nD1X1vLv/JLlxRPZd96JguCad58/vxYwJ5z/Chmad404iWay6WTczU5JCJAm6FU1ibcuDMm6se27P\ni+OOIFkukVk3Ihnh00MHYl4ad4waMy+la1Eh2xu25KsOx8UdR7JQdUM3f3L3n5rZy8BeE5Pd/YLI\nkonU0Kxjro47wj5xjEEvXU5Rt3N4cdBTcceRLFTd0M2e37r7og4iUhvtVsxmS9P2bGnSLu4oNWfG\n4oLT6bJI8+klGlVOr3T3meH12wS9bdYD64Cp4WMiaeGCl69m8D9+EHeMfba4oB/7bV5Oy/VFcUeR\nLJRom+IBQBHwEMF5XheY2XlRBhNJVOOtqzhgxSyKumbQbJtyvulPv0htiyX5Ej3xyP8B/dz9dHc/\nDegHPBBdLJHEdV04GYCi7ufGnGTfrWl1CFsa70+nZVPjjiJZKNE2xZvdfUGZ+wsJGpuJxK5b0SS2\nNWzFina94o6y78wYdfU0Nu7XKe4kkoWqm3VzYXhzhplNAJ4lmH3zfeDDiLOJVM+dbkWTWNj1LDwv\nP+40tbKheUHcESRLVbdF/90yt1cCp4W3VwMNI0kkUhNmjBo6lTq7d8SdpNbq7NrOOZN+waIuZzC/\nx0Vxx5EsUt0BU2q+IWlvY/PsaB+wu04DDvv0RRruWK9CL0mV0Bi9mTUAhgI9gQZ7Hnf3qyLKJZKY\nu+7isPk9mH/YhdUvm+7C+fTqTy/Jluism6eAdgRnnHqb4IxT2hkr8dqxA+6+m85L3ok7SdIsKuhH\n0y1f02rt53FHkSySaKHv7u6/BraG/W8GAH2iiyWSgPfegx07MqtbZTW+mU+v/vSSRIkW+l3h9QYz\nOxxoBrSNJpJIggoLoW5dlnQ+Ne4kSbOuZXeWdehDXunuuKNIFkl0Hv1IM2sB/BoYT3DGqV9Hlkok\nEYWF0LdvRp1RqlrhfHqRZEqo0Lv7qPDm20DX6OKIJKi4ONhhec45337ezCbu5HkJpXmJbouJVC7R\nXjetzOxhM5tlZjPN7E9m1irqcCKVql8fZs+G/8mc0wYmqtG2NdzyQCeOmfl43FEkSyQ6Rv8MsAq4\nCBgMrAHGRRVKpFoenh4hC6cgbmvYCjejYMlbcUeRLJFooW/v7r9z90Xh5S5g/yiDiVTKHY44An7/\n+7iTROOb+fRvffsPTaQWEi30k8zsEjPLCy8XAxOjDCZSqS++gLlzoUWLuJNEZnFBP5psXUWbNfPj\njiJZoMpCb2abzWwTcA3wd2BneHkGGBZ9PJEKFBYG12efHW+OCGk+vSRTdb1umqYqiEjCJk+GggLo\n1i3uJJFZ37wL7570y8xuvSxpI+G5W2Z2AbDnyJS33P2VapYfDXwHWOXuh1fwvAEPAucD24Ar3H1W\nonkkR+3eDVOmwMUXZ+WO2G+Y8cZZ98SdQrJEotMr/wDcDMwLLzebWXW/hWOA/lU8fx5wUHgZBvwl\nkSyS43bsgJtvhiFD4k4SOSstof2KWTTesjLuKJLhEt0Zez5wtruPdvfRBAV8QFVf4O7vEJxIvDLf\nA570wDSguZm1TzCP5KomTeDOO+GMM+JOErlmm5Zy7chj6TnvubijSIZLtNADNC9zu1kSXrsDsLTM\n/WXhYyKVmz4dtm2LO0VKbGhewIZmnbVDVmot0UJ/DzDbzMaY2VhgJnB3dLH+k5kNM7MZZjZj9erV\nqXpZSTebN8PJJ8Pvfhd3kpTZM5/evDTuKJLBqi304U7T94ATgBeA54G+7l7bI2OXA2XPhNwxfGwv\n7j7S3Xu7e+82bdrU8mUlY739drAzNounVZa3qKAfjbavpc2quXFHkQxWbaF3dwcmuPsKdx8fXr5O\nwmuPBy63wAnARndfkYT1SrYqLIQGDeDEE+NOkjJLCoLTNHdZ/GbMSSSTJTq9cpaZHefuHya6YjN7\nGjgdaG1my4DfAnUB3H0EMIFgJ+8CgumVOj+tVG3yZDj11KDY54gNzQsYe/kbLO9wfNxRJIMlWuj7\nAD8ys8XAVsAINvaPrOwL3L3K+W/hJ4UbEnx9yXXLl8O8eXBl7m0PLOqS/TOMJFqJFvpzI00hUp12\n7eDDD+GAA+JOknJNNq+g98zHmHPED4GD444jGajKQm9mDYDhQHdgDvCEu+scZ5J6+fnQu3fcKWKR\nX7qL09++g+0NWqBCL/uiup2xY4HeBEX+POD/Ik8kUp473HprsEWfgzY2O5B1LbqqP73ss+qGbnq4\n+xEAZvYE8EH0kUTKmTMH7rsPevSA446LO00sFnc+ncM+fRFKSyGvJsc5ilS/Rf/N2Tg1ZCOxmTw5\nuM6h+fPlLe7Sj4Y71sMnn8QdRTJQdYX+KDPbFF42A0fuuR32qReJXmEhHHoodOwYd5LYLCrox866\njWHRorijSAaqstC7e7677xdemrp7nTK390tVSMlhxcXBEbE5vDUPsHm/Dtz7/9bCoEFxR5EMpME+\nSW+LFkHz5jlf6AFK6tQPbug8slJDKvSS3g49NDhY6vzz404Su4bb1kKvXjBqVNxRJMOo0Ev6Mwvm\n0ee47Q1bwqZN8OKLcUeRDKNCL+lr3brg3LAvvRR3kvRgBgMHwhtvBAVfJEEq9JK+pkyBJUtAram/\nNWgQ7NwJr70WdxLJICr0kr4KC6FpUzhenRu/0bdv8I9Pn3KkBhJtaiaSeoWF0K8f1K0bd5L0kZ8P\nt98OLVvGnUQyiAq9pKeFC4OplbfcEneS9HP99XEnkAyjoRtJX9deC/37x50iPS1bBm+9FXcKyRDa\nopf01LUrjBgRd4r0dcst8O67wTEGanIm1dBviKSfkhKYPTvo1CgVGzgQvv4apk+PO4lkABV6ST+z\nZsExx8Bzz8WdJH0NGBDspNbsG0mACr2kn8LC4Lpfv3hzpLNmzYLvz4svqveNVEuFXtJPYSEcdRS0\nbRt3kvQ2aBAsWKDWxVItFXpJL1u3wvvvq1tlIoYMga++CnZci1RBs24kvbzzDuzalfaF/vbb405A\nMHzTrFncKSQDaIte0supp8Krr8Ipp8SdJDN89BGcdx4sXRp3EkljKvSSXho3DnrPN2wYd5LM0LAh\nvP46/POfcSeRNKZCL+lj5cpgTOTLL+NOkjkOOSQ4OYumWUoVVOglfRQWwh13wOrVcSfJLIMGBe0Q\n1q2LO4mkKRV6SR+TJ0OrVsHp8iRxAwcGRxO/+mrcSSRNqdBLenAPtujPPFO9W2qqd+9gv0bjxnEn\nkTSl6ZWSHubPD+aEp/m0yrSUl6eteamSNp0kPXz2GTRqBGedFXeSzLV1K6xYEXcKSUMq9JIeBg2C\n9euDk4FLzZWWQvfucNttcSeRNKRCL+mjXr24E2SuvDw44wwYPx527447jaQZFXqJ3/vvB22J586N\nO0lmGzQI1q4Nvp8iZajQS/wmToSPP4YOHeJOktn694f69XXwlOxFhV7i5Q4vvAB9+kDz5nGnyWxN\nmgSzltSjXsrR9EqJ1+TJwZDNmDFxJ8kOd94J+flxp5A0E+kWvZn1N7PPzGyBmf2yguevMLPVZvZR\neLk6yjyShu6/H/bfHy65JO4k2aFXLzjySDCLO4mkkci26M0sH/gzcDawDPjQzMa7+7xyi45z9xuj\nyiFpbuhQ2LYtGFuW5Hj/fXjtNbjrrriTSJqIcov+eGCBuy90953AM8D3Inw9yUSDB8Pll8edIrtM\nnw533w0LF8adRNJElIW+A1D2bAjLwsfKu8jMPjGzf5hZpwjzSDpZsybY4lTHxeQbODC41uwbCcU9\n6+ZloMDdjwQKgbEVLWRmw8xshpnNWK0WttlhxAj49a/h66/jTpJ9unYNxulV6CUUZaFfDpTdQu8Y\nPvYNd1/r7sXh3VHAsRWtyN1Huntvd+/dpk2bSMJKChUXwyOPBPO+e/SIO012GjQI3nsPVq2KO4mk\ngSgL/YfAQWbWxczqAZcA48suYGbty9y9AJgfYR5JF888E5xN6mc/iztJ9ho4EDp2hKKiuJNIGohs\n1o277zazG4GJQD4w2t3nmtmdwAx3Hw/8xMwuAHYD64ArosojacIdHngAevZUS+IoHXUULFmiaZYC\nRHzAlLtPACaUe+w3ZW7/N/DfUWaQNLNpE3TqBBdeqCIUpT3f25KS4J9rHR0bmcv005fUatYMXn45\n7hQZ6/bbE1+25boFXDX6JCac/2cufnZwZJkk/anQS+osWwY7dwazQsqpSQGTxGxoXoB5KYd++hKg\nQp/L4p5eKbnk97+Hww8Phm8kcqV5dfj84O9y8OevBP9gJWep0EtqrFsHY8cGPW322y/uNDnj00MH\n0qB4I7z9dtxRJEYq9JIaI0cGPW00pTKlirqezc66jYLWxZKzVOglejt3wsMPByf+PuKIuNPklN11\nGzLxnPvVHTTHqdBL9GbODHrbaGs+FjN7Xwunnhp3DImRCr1Er2/f4OCd/v3jTpK7li6FK6+E9evj\nTiIx0PRKidaOHdCgAbRrF3eS3LZmDTz5ZPCz+Mtf4k4jKaYteonWkCFw0UVxp5BeveAnP4HHHoNp\n0+JOIymmQi/RWbAA/vlPOOywuJMIBOeTPeAAGD4cdu+OO42kkAq9ROehh4IeKzfcEHcSAWjaNPiZ\nfPwxPPpo3GkkhVToJRobNsDo0cHQTfv21S8vqTFoEDz4IFx6adxJJIW0M1ai8cQTsHWrplSmG7Ng\nrB6gtBTytK2XC/RTlmgMGwbjxsHRR8edRCqybBkcd5w6ieYIFXqJRtOmcPHFcaeQyuy/f3BKxxtv\nDD55SVZToZfkcocf/xheeCHuJFKVunWD+fRffhnMxpGspkIvyTV1anBgzooVcSeR6pxyClx1Fdx/\nP8yZE3caiZAKvSTXAw9A8+bBVr2kv3vvDc76dd99cSeRCGnWjSTPokXBkM2tt0KTJnGnkUS0bg1v\nvKGD2rKcCr0kz8MPB9P1brwx7iRSE0cdFVxv3hwcMduiRbx5JOlU6CVpxi07ibYnNePtUR3jjiI1\nVVwcFPxTT4UxY+JOI0mmMXqpvZISKC1lfo+LePv038adRvZF/frBUcxjx8Jbb8WdRpJMhV5qp7g4\nKBA//3kwtVIy1223QZcucN11wc9VsoYKvey7zZthwAB47jno2DE4vF4yV6NG8Mgj8OmnmoWTZVTo\nZd+sXg39+gUf88eODbboJfOdfz4MHhz0rNcntKyhnbFScyUlcOaZ3/abHzAg7kSSTGPGBFv3+oSW\nNVTopeby8+GOO6BtWzjppLjTSLI1bhxcL10anOv35JPjzSO1pkIviXvvveCPf8iQoK+5ZLcf/Qi+\n+ALmzw+OnpWMpTF6SczLL8PZZ8Pdd8OuXXGnkVS47z74+uugf/2OHXGnkVpQoZfqjRkTbMEffji8\n+WbQ+VCy33HHwX/9V9Ck7tBD4dln404k+0iFXqr2xz/ClVcGM2ymTIE2beJOJKl0zz1BL5wWLeCd\nd+JOI/tIY/RStc2bgxOIPPlkcPSkZKTbb6/N154BM2Z8exDVu+8GJxn/wx+gW7ek5JNoqdDLXu78\nzW6ar1/EulYHgd2BHer4Pfrwl9Py84MplwBFRTBhQjC19qab4Fe/UiO0NKe/XvlP27bxg3GDGDr6\nRBpuXwdmuOnXRMq44orgGIrLLw/OP9C9O4waFXcqqYK26CWwcmWwo/XBBzn48+m8ev6f2d6wZdyp\nJA1UPOzTHjqOYv9hN3FO4S9Y8OxGpi7j26Npw4OtajNkJMmjQp+r1q6FVauCE05s3w4HHgg7d0KL\nFjw3eBzzen4/7oSSAVa2O4qnfjQJIyjwR37yV46ZPYqJ59zPigOOjTmd7BHpZ3Iz629mn5nZAjP7\nZQXP1zezceHz082sIMo8OW3TJnjllaAnTa9eweyZa64JnmvYEJ54Aj74AFatUpGXmikzvOd5+bRZ\nPZ9rH+/NoBcvCz4lfvVVzAHFPKLGRWaWD3wOnA0sAz4Ehrj7vDLLXA8c6e7DzewSYJC7/6Cq9fbu\n3dtnzJgRSeZscvdt22i3YjZLDwxaFPzw7wM4+IsJ7M6vz9JOJ7Koyxks7HoWyzqeEHNSyTb1d2zk\n5Pf+QN9pD1CnpDhokvbcc8GTl1wSnL6wWzfo2vXb6z07eqVGzGymu/eudrkIC31f4HZ3Pze8/98A\n7n5PmWUmhstMNbM6wNdAG68iVFYUevfgUloanHovLy84hVtxcfDYnks4lEK9erB8OcyeHUx3LHu5\n6SZo1SqYAfH448FjGzdSMmce+aW7+N9bV7OtUWsO/PI98kp2saxTX3bXaRD3d0ByQOOtq2i7cg47\n6zdleYfjyS/ZydWjTqDF+iIaFG/6ZrmpJ/yMiefeT51d2/nOq8NZ37wrG1p0YdBlTYLf/cMPh4KC\nYIjx3/8OpvnWq/ftpWXL4B/Fnr+b/PycaciWaKGPcoy+A7C0zP1lQJ/KlnH33Wa2EWgFrEl6mrVr\ng1+W8n77W/jFL+DLL6Fnz72f/+MfYfhwmDsXjj9+7+dHjIDLLoPp04ODisr729+Co0oLC6F//+AX\nsazXX4dzzw0K9eDBe335qKFTWdbxBI6ePYmB46/a6/lHV17Eqv1bccQnW+g7awU76zVhZ72OrD7h\nHBZ1OYPiek0B+PJANaaS1NrauC2Lup75zf2S/Ho8du0scKfh9nW0WL+QluuLWNeyOxD8Y+iyaApH\nb3oy+IKXgqsJ/R/igz430XblAq4fsfff4EsXjOajXlfSaek0ho4u02TPLLg89xxceGHwN7in0+qe\n58yC9h5nnQUvvRT09ynvjTegTx946qngpCzlffAB9OgR1IJbb937+blzg31g990XNAMsb/HiYGMt\nQlFu0Q8G+rv71eH9y4A+7n5jmWX+HS6zLLxfFC6zpty6hgHDwruHAJ9FEjpxrYnin1Fm0HvPPbn6\nviH933tnd6/2cPUot+iXA53K3O8YPlbRMsvCoZtmwNryK3L3kcDIiHLWmJnNSOTjUjbSe8+9956r\n7xuy571HOevmQ+AgM+tiZvWAS4Dx5ZYZD/w4vD0YmFLV+LyIiNRcZFv04Zj7jcBEIB8Y7e5zzexO\nYIa7jweeAJ4yswXAOoJ/BiIikkSRHjDl7hOACeUe+02Z2zuATJy0nTbDSDHQe889ufq+IUvee2Q7\nY0VEJD2oW5WISJZToU+AmX3fzOaaWamZVboHvrqWD5nIzFqaWaGZfRFeV9iP1sxKzOyj8FJ+p3vG\nyOW2HQm89yvMbHWZn/PVceSMgpmNNrNV4ZTvip43M3so/N58YmbHpDpjbajQJ+bfwIVApafYCVs+\n/Bk4D+hHiXtDAAAF10lEQVQBDDGzHqmJF6lfAm+4+0HAG+H9imx396PDywWpi5c8Cf4MhwLr3b07\n8ABwb2pTRqMGv7/jyvycs6k38RigfxXPnwccFF6GAX9JQaakUaFPgLvPd/fqDtI6Hljg7gvdfSfw\nDPC96NNF7nvA2PD2WGBgjFmilsjPsOz34x/AmWZZcbx9tv7+JsTd3yGY+VeZ7wFPemAa0NzM2qcm\nXe2p0CdPRS0fOsSUJZn2d/cV4e2vgf0rWa6Bmc0ws2lmlqn/DBL5Gf5H2w5gT9uOTJfo7+9F4dDF\nP8ysUwXPZ6uM/vtWP/qQmU0G2lXw1G3u/s9U50mlqt572Tvu7mZW2TStzu6+3My6AlPMbI67FyU7\nq8TqZeBpdy82s2sJPtmcEXMmSYAKfcjdz6rlKhJp+ZCWqnrvZrbSzNq7+4rwo+qqStaxPLxeaGZv\nAb2ATCv0SWvbkYGqfe/uXvZ9jgL+NwW50kXG/n2Dhm6SKZGWD5mobJuKHwN7fboxsxZmVj+83Ro4\nCZhXfrkMkMttO6p97+XGpC8A5qcwX9zGA5eHs29OADaWGdJMf+6uSzUXYBDBmFwxsBKYGD5+ADCh\nzHLnE5xspYhgyCf27El4760IZtt8AUwGWoaP9wZGhbdPBOYAH4fXQ+POXYv3u9fPELgTuCC83QB4\nDlgAfAB0jTtzCt/7PcDc8Of8JnBo3JmT+N6fBlYAu8K/9aHAcGB4+LwRzEoqCn/He8eduSYXHRkr\nIpLlNHQjIpLlVOhFRLKcCr2ISJZToRcRyXIq9CIiWU6FXjKCmd0WdhD9JOyc2Cd8/Kdm1iiJrzPc\nzC5P4vpam9kuMxtey/UUVNZZUaQ6ml4pac/M+gL3A6d7cPh9a6Ceu39lZosJ5jSvScLr1PGgf03S\nmNl1wA+BUnc/rRbrKQBecffDkxRNcoi26CUTtAfWuHsxgLuvCYv8TwgOWnvTzN4EMLNzzGyqmc0y\ns+fMrEn4+LFm9raZzTSziXuO8jSzt8zsT2Y2A7jZzG43s1+Uee5eM/vAzD43s1PCxxuZ2bNmNs/M\nXgz70ld2noIhwM+BDmbWcc+DZrbFzO42s4/DRnD7h493C+/PMbO7zGxL+RWaWb6Z/dHMPgw/4Vyb\nlO+yZC0VeskEk4BOYbF91MxOA3D3h4CvgH7u3i/c0v8VcJa7HwPMAG4xs7rAw8Bgdz8WGA3cXWb9\n9dy9t7v/XwWvXcfdjwd+Cvw2fOx6gp70PYBfA8dWFDrs7tje3T8AngV+UObpxsA0dz+K4DwH14SP\nPwg86O5HEByhWZGhBIfgHwccB1xjZl0qWVZEhV7Sn7tvISimw4DVwDgzu6KCRU8gOGnG+2b2EUFP\nms7AIcDhQGH4+K8ImlLtMa6Kl38hvJ4JFIS3Tybo1467/xv4pJKv/QFBgSdcfkiZ53YCr1Sw7r4E\nLRYA/l7Jes8h6LvyETCdoE3FQVW8B8lx6l4pGcHdS4C3gLfMbA5BER9TbjEDCt19yH88aHYEMNfd\n+1ay+q1VvHRxeF1Czf9ehgDtzOzS8P4BZnaQu38B7PJvd5DVdN0G3OTuE2uYR3KUtugl7ZnZIWZW\ndov1aGBJeHsz0DS8PQ04ycy6h1/X2MwOBj4D2oQ7dTGzumbWsxaR3gcuDtfVAziigswHA03cvYO7\nF7h7AUFTsCHlly1nGnBRePuSSpaZCFwXDklhZgebWeMavwvJGSr0kgmaAGPDnZ+fEAzP3B4+NxJ4\n3czedPfVwBXA0+FyUwk6LO4kaCl8r5l9DHxE0HFzXz1K8I9jHnAXQUfHjeWWGQK8WO6x56m+0P+U\nYL/CJ0D3CtYLQS/4ecCscMrlY+jTuVRB0ytFasiCE2nXdfcdZtaNoH3zIeE/lNquuxHBidbdzC4B\nhrh7zpy7VaKhrQCRmmtEMKWzLsF4+fXJKPKhY4FHzMyADcBVSVqv5DBt0YuIZDmN0YuIZDkVehGR\nLKdCLyKS5VToRUSynAq9iEiWU6EXEcly/x+lwhxNkAwSDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4f066cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "\n",
    "num_bins = 20\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(angles, num_bins, normed=1, facecolor='blue', alpha=0.5)\n",
    " \n",
    "# add a 'best fit' line\n",
    "mu = np.mean(angles)\n",
    "sigma = np.std(angles)\n",
    "y = mlab.normpdf(bins, mu, sigma)\n",
    "\n",
    "\n",
    "plt.plot(bins, y, 'r--')\n",
    "plt.xlabel('Steering Angle')\n",
    "plt.ylabel('Probability')\n",
    "# plt.title('Histogram of steering angles')\n",
    " \n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vast majority of steering angles are focused in the middle.  \n",
    "This will bias our car toward steering down the middle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator function for loading batches of data into memory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "samples = []\n",
    "\n",
    "with open(data_loc + 'driving_log.csv') as csv_file: \n",
    "    \n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    \n",
    "    num_samples = len(samples)\n",
    "    \n",
    "    while 1: \n",
    "        # Loop forever so the generator never terminates\n",
    "        \n",
    "        shuffle(samples)\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            \n",
    "            correction = 0.2\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                for i in range(3): \n",
    "                    # this is to get center, left and right images\n",
    "\n",
    "                    path = data_loc + 'IMG/' + batch_sample[i].split('/')[-1]\n",
    "                    image = cv2.imread(path)\n",
    "                    \n",
    "                    angle = float(batch_sample[3])\n",
    "                    \n",
    "                    # add correction to angle based on image\n",
    "                    if i==1:\n",
    "                        angle = angle + correction\n",
    "                    \n",
    "                    elif i==2:\n",
    "                        angle = angle - correction                    \n",
    "                    \n",
    "                    # add image and associated angle to list\n",
    "                    images.append(image)\n",
    "                    angles.append(angle)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:37: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., validation_steps=1608, steps_per_epoch=6429, validation_data=<generator..., verbose=1, epochs=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   8/6429 [..............................] - ETA: 24:46 - loss: 6.3666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fca6e5c92c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                                      \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                      \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                                     )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2081\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Convolution2D\n",
    "\n",
    "\n",
    "# generate\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "# init\n",
    "model = Sequential()\n",
    "\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, \n",
    "                 input_shape=(160,320,3),\n",
    "                 output_shape=(160,320,3)\n",
    "                )\n",
    "         )\n",
    "\n",
    "# crop images to reduce noise, returns img of shape (80,320,3)\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "\n",
    "# flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully-connected\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit  \n",
    "history_object = model.fit_generator(generator = train_generator, \n",
    "                                     samples_per_epoch = len(train_samples), \n",
    "                                     validation_data = validation_generator,\n",
    "                                     nb_val_samples = len(validation_samples), \n",
    "                                     nb_epoch=5, \n",
    "                                     verbose=1\n",
    "                                    )\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced model \n",
    "\n",
    "Our model will be based on an architecture previously developed at NVIDIA.  \n",
    "\n",
    "![NVIDIA Self Driving Car Architecture](https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/08/cnn-architecture-624x890.png)\n",
    "\n",
    "For more information, see the following [link](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nVidiaModel():\n",
    "    \"\"\"\n",
    "    Creates nVidea Autonomous Car Group model\n",
    "    \"\"\"\n",
    "    \n",
    "    # init\n",
    "    model = Sequential()\n",
    "\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "    # crop images to reduce noise, returns img of shape (80,320,3)\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "    \n",
    "    model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  app.launch_new_instance()\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/fqaiser94/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., validation_steps=1608, steps_per_epoch=6429, validation_data=<generator..., verbose=1, epochs=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   7/6429 [..............................] - ETA: 2:02:47 - loss: 0.0866"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2bfc09ec02d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      \u001b[0mnb_val_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                      \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                                     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D\n",
    "\n",
    "# generate\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "# generate model\n",
    "model = nVidiaModel()\n",
    "\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit  \n",
    "history_object = model.fit_generator(generator = train_generator, \n",
    "                                     samples_per_epoch = len(train_samples), \n",
    "                                     validation_data = validation_generator,\n",
    "                                     nb_val_samples = len(validation_samples), \n",
    "                                     nb_epoch=5, \n",
    "                                     verbose=1\n",
    "                                    )\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
